import streamlit as st
import openai
import pandas as pd
import jieba
from pypinyin import pinyin, Style
import re

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏µ‡∏ô‡∏Ñ‡∏≥
def clean_and_tokenize(text):
    # ‡∏•‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    text = re.sub(r"[^\u4e00-\u9fff\s]", "", text)  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏µ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
    text = re.sub(r"\s+", " ", text).strip()  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ jieba
    tokens = jieba.cut(text, cut_all=False)
    return " ".join(tokens)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å API Key
st.sidebar.title("API Settings")
api_key = st.sidebar.text_input("Enter your OpenAI API key", type="password")

if api_key:
    openai.api_key = api_key

    st.title("LunaLexis üåñ")
    st.subheader("Introduction to the App ü•Æ")
    st.text("""
    Welcome to the NLP Application with Preprocessing, an interactive tool designed
    to assist learners and enthusiasts of the Chinese language in exploring and
    analyzing text. This application integrates advanced natural language processing
    techniques with OpenAI's GPT capabilities to deliver a comprehensive suite of features:
    """)
    st.text(' ')
    st.text("1. Pinyin Conversion\n2. Summarization\n3. HSK Vocabulary Extraction")
    st.text(' ')

    # ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠
    st.header("Manual Input üêâ")
    user_input = st.text_area("Enter your Chinese text here:", height=150)
    st.subheader("Select HSK Level üêâ")
    hsk_level = st.selectbox("Choose the HSK difficulty level (1-6):", ["HSK 1", "HSK 2", "HSK 3", "HSK 4", "HSK 5", "HSK 6"])

    if st.button("Process Manual Input"):
        if user_input.strip():
            try:
                # 1. ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏µ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                cleaned_text = clean_and_tokenize(user_input)

                # 2. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏ô‡∏≠‡∏¥‡∏ô
                pinyin_text = ' '.join([syllable[0] for syllable in pinyin(user_input, style=Style.TONE)])

                # 3. ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "user", "content": f"Please summarize the following Chinese article into English, focusing on the main ideas and key information: {user_input}"}
                    ]
                )
                summary_text = response.choices[0].message["content"].strip()

                # 4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                keyword_response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {
                            "role": "user",
                            "content": f"""
Extract 10 interesting keywords from the following Chinese text. 
Each keyword must strictly match the {hsk_level} level as defined by the official HSK vocabulary standard. 
Avoid words outside this level. 
Format the response as a table with '|' separating columns.

Here is an example for HSK 1 level:
‰Ω†Â•Ω          | n«ê h«éo  | hello  
Ë∞¢Ë∞¢          | xi√® xi√® | thank you  

The keywords extracted should match the following criteria:
1. The word must belong to the {hsk_level} vocabulary and be relevant to the context.
2. If {hsk_level} is HSK 1, use only HSK 1 vocabulary and skip comparisons with previous levels.
3. For levels HSK 2-6, the word must belong to the {hsk_level} vocabulary and not exist in any previous HSK levels.
4. Select common and relevant words from the text that fit the context.
5. Avoid advanced words or phrases if they exceed the selected level.

Text:
{cleaned_text}
"""
                        }
                    ],
                    max_tokens=300
                )
                keywords_table = keyword_response.choices[0].message["content"].strip()

                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô DataFrame
                keywords_list = []
                for line in keywords_table.split("\n"):
                    if "|" in line:  # ‡πÉ‡∏ä‡πâ '|' ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                        parts = [col.strip() for col in line.split("|")]
                        if len(parts) == 3 and parts[0] != "Keyword":  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                            keywords_list.append(parts)

                if keywords_list:
                    df_keywords = pd.DataFrame(keywords_list, columns=["Chinese Word", "Pinyin", "English Translation"])
                else:
                    st.warning("No keywords were extracted. Please check the input or API response format.")
                    df_keywords = pd.DataFrame(columns=["Chinese Word", "Pinyin", "English Translation"])  # DataFrame ‡∏ß‡πà‡∏≤‡∏á

                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                st.subheader("Pinyin üßß")
                st.write(f"{pinyin_text}")

                st.subheader("Summary (English) ü•¢")
                st.write(f"{summary_text}")

                st.subheader("Interesting Keywords Table üÄÑÔ∏è")
                st.dataframe(df_keywords)

            except Exception as e:
                st.error(f"Error: {e}")
        else:
            st.error("Please enter some text!")
